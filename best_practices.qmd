---
title: "Best Practice Manuals"
---
```{r libraries, include = FALSE, message = FALSE, echo = FALSE}
library(librarian)
librarian::shelf(tidyverse, cran_repo = 'https://cran.r-project.org')
```

### Welcome!

This page contains the collected best practice tips of the NCEAS Scientific Computing Support Team. More will be added over time and feel free to post [an issue](https://github.com/NCEAS/scicomptasks/issues) if you have a specific request for a section to add to this document.

Please feel free to reach out to our team (see [here](https://www.nceas.ucsb.edu/programming-support)) if you have any questions about this best practices manual and/or need help implementing some of this content.

Check the headings below or in the table of contents on the right of this page to see which tips and tricks we have included so far and we hope this page is a useful resource to you and your team!

## Suggested Tools & Programs

At NCEAS we are almost exclusively working on collaborative projects where we synthesize existing data to draw larger inferences than any single data set would allow. Because of this, we strongly recommend that each tool used by a team accomplish as many purposes as possible to avoid a project accruing endless "one off" tools that fit a specific purpose but do not accomplish any other tasks. **Streamlining your workflow to just a few broadly useful programs also helps train new team members and ensure that within team protocols are clear and concise to follow.**

The analytical software options available at NCEAS follow directly from this ethos. Although occasionally providing specialty programs (upon request), we have otherwise carefully assembled a powerful lineup of *scripted*, *cross-platform*, *scalable* applications that are *well-supported*, generate *robust results*, and permit *batch processing*. Although these packages require an initial time investment to learn, and may seem intimidating to scientists familiar with only "point-and-click" software, we strongly argue that the long-term payoff is well worth the time investment at the start.

### Collaborative Tools

We strongly recommend that you use **[GitHub](https://github.com/)** both for its capability to visualize *version control* with [`git`](https://pages.github.nceas.ucsb.edu/NCEAS/Computing/git.html) and for its broader value as an integrated project management system.

### Software

**General Analytical Software**

- [R](https://datacarpentry.org/R-genomics/index.html)
    - Note that we strongly suggest using R through [RStudio](https://www.rstudio.com/) as it contains several extremely user-friendly facets that are absent from R's somewhat minimalist base program
- [Python](https://swcarpentry.github.io/python-novice-inflammation/setup.html)

**Spatial Analytical Software**

- [Data Carpentries Geospatial Workshop](https://datacarpentry.org/geospatial-workshop/setup.html)
- [Geographic Resources Analysis Support System (GRASS)](https://pages.github.nceas.ucsb.edu/NCEAS/Computing/grass.html)
- [Quantum GIS (QGIS)](https://pages.github.nceas.ucsb.edu/NCEAS/Computing/quantum_gis.html)
- [PostGIS](https://pages.github.nceas.ucsb.edu/NCEAS/Computing/postgis.html)
- [Geospatial Data Abstraction Library (GDAL / OGR)](https://pages.github.nceas.ucsb.edu/NCEAS/Computing/gdal.html)

**Relational Databases**

- [SQLite](https://swcarpentry.github.io/sql-novice-survey/)

**Code Versioning**

- [`git`](https://swcarpentry.github.io/git-novice/)
    - Again, we strongly recommend using **[GitHub](https://github.com/)** if you use `git` (similarly to R versus RStudio, you *can* use `git` without GitHub but GitHub contains several quality of life improvements and additional functionalities)

**Servers**

- [Unix Shell](https://swcarpentry.github.io/shell-novice/)
    - Note this is also sometimes called the "command line" or--on Macs--"the Terminal"

## R Scripts versus R Markdowns

When coding in R, either R scripts (.R files) or R markdowns (.Rmd files) are viable options but they have different advantages and disadvantages that we will cover below.

### R Scripts - Positives

R scripts' greatest strength is their flexibility. They allow you to format a file in whatever way is most intuitive to you. Additionally, R scripts can be cleaner for `for` loops insofar as they need not be concerned with staying within a given code chunk (as would be the case for a .Rmd). Developing a new workflow can be swiftly accomplished in an R script as some or all of the code in a script can be run by simply selecting the desired lines rather than manually running the desired chunks in a .Rmd file. Finally, R scripts can also be a better home for custom functions that can be `source`d by another file (even a .Rmd!) for making repeated operations simpler to read.

### R Scripts - Potential Weaknesses

The benefit of extreme flexibility in R scripts can sometimes be a disadvantage however. We've all seen (and written) R scripts that have few or no comments or where lines of code are densely packed without spacing or blank lines to help someone new to the code understand what is being done. R scripts can certainly be written in a way that is accessible to those without prior knowledge of what the script accomplishes but they do not *enforce* such structure. This can make it easy, especially when we're feeling pressed for time, to exclude structure that helps our code remain reproducible and understandable.

### R Markdowns - Positives

R markdown files' ability to "knit" as HTML or PDF documents makes them extremely useful in creating outward-facing reports. This is particularly the case when the specific code is less important to communicate than visualizations and/or analyses of the data but .Rmd files do facilitate `echo`ing the code so that report readers can see how background operations were accomplished. The code chunk structure of these files can also nudge users towards including valuable comments (both between chunks and within them) though of course .Rmd files do not enforce such non-code content.

### R Markdowns - Potential Weaknesses

R markdowns can fail to knit due to issues even when the code within the chunks works as desired. Duplicate code chunk names or a failure to install LaTeX can be a frustrating hurdle to overcome between functioning code and a knit output file. When code must be re-run repeatedly (as is often the case when developing a new workflow) the stop-and-start nature of running each code chunk separately can also be a small irritation.

### Script vs. Markdown Summary

Taken together, both R scripts and R markdown files can empower users to write reproducible, transparent code. However, both file types have some key limitations that should be taken into consideration when choosing which to use as you set out to create a new code product.

## File Paths

This section contains our recommendations for handling **file paths** on NCEAS analytical server. When sharing code collaboratively (e.g., with GitHub) managing the difference between your folder structure and those of your colleagues can be tackled in a variety of ways. Failing to account for this can result in annoying errors where content is either not read in successfully or is exported to the wrong folder. For content inside your working directory, we recommend using relative paths. However sometimes you need to read files from folders that are outside your working directory, for example large datasets shared among your team members.

Below are our recommendations for file path management in a team context; we hope they help!

### 1) Preserve File Paths as Objects

First and foremost, we recommend that you begin each script (just after loading your libraries) by saving all the paths to your files as objects. This makes it easy for each new user to remember that they might need to alter those objects so that data are read in and saved out to the appropriate places.

```{r path_objects}
my_path <- "path/to/my/file/"
my_path
```

### 2) Use `file.path()` to Make Path Objects

`file.path()` is a useful base R function that automatically accounts for the fact that Mac and PC operating systems use different slashes between folder names to indicate a path (one uses '/' and the other uses '\\')

```{r file.path_demo}
my_path <- file.path("path", "to", "my", "file")
my_path
```

Note that while you could use `paste(..., sep = '/')` instead, it does not account for the different slash between Mac and PC so `file.path()` is preferable.

### 3) Use Path Objects when Reading/Writing Data

Now that you've saved your paths as objects using `file.path()` to account for operating system differences, you should use them during import/export steps! To do this, just wrap the argument (i.e., part of the function) that deals with the file name/path in another call to `file.path()` with the object you created earlier and the name of the file to import/export. See below for two examples:

```{r import, eval = F}
# Import
my_raw_data <- read.csv(file = file.path(my_path, "raw_data.csv"))

# Export
write.csv(x = data_object, file = file.path(my_path, "tidy_data.csv"))
```

### File Paths Summary

We strongly recommend preserving your file paths as objects at the start of your scripts (using `file.path()`) to ensure that your scripts can be shared as easily as possible among your team without issues due to user-specific folder names or computer operating system interrupting the work that you set out to do.

## Package Loading

Loading packages / libraries in R can be cumbersome when working collaboratively because there is no guarantee that you all have the same packages installed. While you could comment-out an `install.packages()` line for every package you need for a given script, we recommend using the R package `librarian` to greatly simplify this process!

`librarian::shelf()` accepts the names of all of the packages--either CRAN or GitHub--installs those that are missing in that particular R session and then attaches all of them. See below for an example:

To load packages typically you'd have something like the following in your script:

```{r library_og_method, eval = FALSE}
## Install packages (if needed)
# install.packages("tidyverse")
# install.packages("devtools")
# devtools::install_github("NCEAS/scicomptools")

# Load libraries
library(tidyverse); library(scicomptools)
```

With `librarian::shelf()` however this becomes *much* cleaner!

```{r shelf_demo, eval = FALSE}
# Install and load packages!
librarian::shelf(tidyverse, NCEAS/scicomptools)
```

When using `librarian::shelf()`, package names do not need to be quoted and GitHub packages can be installed without the additional steps of installing the `devtools` package and using `devtools::install_github()` instead of `install.packages()`.
