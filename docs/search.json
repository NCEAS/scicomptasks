[
  {
    "objectID": "pkgs.html",
    "href": "pkgs.html",
    "title": "R Package",
    "section": "",
    "text": "While much of the work we do is specific to a given working group or task, sometimes we realize afterwards that our functions have the potential to be useful beyond the scope for which they were initially written. To that end, we have created the R package scicomptools!\n\n\n\nThis package contains a diverse mix of functions for everything from repetitive data wrangling tasks to checking whether you have a token attached for GitHub. In addition, functions that we wrote that are deprecated (usually because their internal workings have been superseded by packages on CRAN) are removed from the package but retained in the GitHub repository in case they are useful to you! All functions–both live and deprecated–are summarized in the README on the GitHub repository so take a look!\n\n\n\nTo install the package in R, use the following:\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"NCEAS/scicomptools\")"
  },
  {
    "objectID": "workshops.html",
    "href": "workshops.html",
    "title": "Workshops",
    "section": "",
    "text": "In addition to the specific task-based support we offer LTER working groups, we can also create and run interactive workshops on data or coding topics. The specific goals of these workshops can be modified to best suit your team and meet all attendees where they are to ensure no one is left behind. While we are always happy to discuss developing new workshops we do have some materials that have already been designed (and tested by other working groups!) and are happy to offer any of these workshops to your group if it is of interest."
  },
  {
    "objectID": "workshops.html#collaborative-coding-with-github",
    "href": "workshops.html#collaborative-coding-with-github",
    "title": "Workshops",
    "section": "Collaborative Coding with GitHub",
    "text": "Collaborative Coding with GitHub\n\nIn synthesis science, collaboration on code products is often integral to the productivity of the group. However, learning to use the software and graphical user interfaces that support this kind of teamwork can be a significant hurdle for teams that are already experts in their subject areas. This workshop is aimed at helping participants gain an understanding of the fundamental purpose and functioning of “version control” systems–specifically GitHub–to help teams more effectively code collaboratively.\nThe full workshop materials can be found here.\nThe GitHub  repository for the workshop can be found here."
  },
  {
    "objectID": "workshops.html#coding-in-the-tidyverse",
    "href": "workshops.html#coding-in-the-tidyverse",
    "title": "Workshops",
    "section": "Coding in the tidyverse",
    "text": "Coding in the tidyverse\n\nFor teams that code using the R programming language, the most familiar tools are often part of “base R” meaning that those functions and packages come pre-loaded when R is installed. Relatively recently the tidyverse has emerged as a comprehensive suite of packages that can complement base R or serve as an alternative for some tasks. This includes packages like dplyr and tidyr as well as the perhaps infamous pipe operator (%>%) among many other tools. This workshop is aimed at helping participants use the tidyverse equivalents of fundamental data wrangling tasks that learners may be used to performing with base R.\nThe full workshop materials can be found here.\nThe GitHub  repository for the workshop can be found here."
  },
  {
    "objectID": "best_practices.html",
    "href": "best_practices.html",
    "title": "Best Practice Manuals",
    "section": "",
    "text": "This page contains the collected best practice tips of the NCEAS Scientific Computing Support Team. More will be added over time and feel free to post an issue if you have a specific request for a section to add to this document.\nPlease feel free to reach out to our team (see here) if you have any questions about this best practices manual and/or need help implementing some of this content.\nCheck the headings below or in the table of contents on the right of this page to see which tips and tricks we have included so far and we hope this page is a useful resource to you and your team!"
  },
  {
    "objectID": "best_practices.html#suggested-tools-programs",
    "href": "best_practices.html#suggested-tools-programs",
    "title": "Best Practice Manuals",
    "section": "Suggested Tools & Programs",
    "text": "Suggested Tools & Programs\nAt NCEAS we are almost exclusively working on collaborative projects where we synthesize existing data to draw larger inferences than any single data set would allow. Because of this, we strongly recommend that each tool used by a team accomplish as many purposes as possible to avoid a project accruing endless “one off” tools that fit a specific purpose but do not accomplish any other tasks. Streamlining your workflow to just a few broadly useful programs also helps train new team members and ensure that within team protocols are clear and concise to follow.\nThe analytical software options available at NCEAS follow directly from this ethos. Although occasionally providing specialty programs (upon request), we have otherwise carefully assembled a powerful lineup of scripted, cross-platform, scalable applications that are well-supported, generate robust results, and permit batch processing. Although these packages require an initial time investment to learn, and may seem intimidating to scientists familiar with only “point-and-click” software, we strongly argue that the long-term payoff is well worth the time investment at the start.\n\nCollaborative Tools\nWe strongly recommend that you use GitHub both for its capability to visualize version control with git and for its broader value as an integrated project management system.\n\n\nSoftware\nGeneral Analytical Software\n\nR\n\nNote that we strongly suggest using R through RStudio as it contains several extremely user-friendly facets that are absent from R’s somewhat minimalist base program\n\nPython\n\nSpatial Analytical Software\n\nData Carpentries Geospatial Workshop\nGeographic Resources Analysis Support System (GRASS)\nQuantum GIS (QGIS)\nPostGIS\nGeospatial Data Abstraction Library (GDAL / OGR)\n\nRelational Databases\n\nSQLite\n\nCode Versioning\n\ngit\n\nAgain, we strongly recommend using GitHub if you use git (similarly to R versus RStudio, you can use git without GitHub but GitHub contains several quality of life improvements and additional functionalities)\n\n\nServers\n\nUnix Shell\n\nNote this is also sometimes called the “command line” or–on Macs–“the Terminal”"
  },
  {
    "objectID": "best_practices.html#r-scripts-versus-r-markdowns",
    "href": "best_practices.html#r-scripts-versus-r-markdowns",
    "title": "Best Practice Manuals",
    "section": "R Scripts versus R Markdowns",
    "text": "R Scripts versus R Markdowns\nWhen coding in R, either R scripts (.R files) or R markdowns (.Rmd files) are viable options but they have different advantages and disadvantages that we will cover below.\n\nR Scripts - Positives\nR scripts’ greatest strength is their flexibility. They allow you to format a file in whatever way is most intuitive to you. Additionally, R scripts can be cleaner for for loops insofar as they need not be concerned with staying within a given code chunk (as would be the case for a .Rmd). Developing a new workflow can be swiftly accomplished in an R script as some or all of the code in a script can be run by simply selecting the desired lines rather than manually running the desired chunks in a .Rmd file. Finally, R scripts can also be a better home for custom functions that can be sourced by another file (even a .Rmd!) for making repeated operations simpler to read.\n\n\nR Scripts - Potential Weaknesses\nThe benefit of extreme flexibility in R scripts can sometimes be a disadvantage however. We’ve all seen (and written) R scripts that have few or no comments or where lines of code are densely packed without spacing or blank lines to help someone new to the code understand what is being done. R scripts can certainly be written in a way that is accessible to those without prior knowledge of what the script accomplishes but they do not enforce such structure. This can make it easy, especially when we’re feeling pressed for time, to exclude structure that helps our code remain reproducible and understandable.\n\n\nR Markdowns - Positives\nR markdown files’ ability to “knit” as HTML or PDF documents makes them extremely useful in creating outward-facing reports. This is particularly the case when the specific code is less important to communicate than visualizations and/or analyses of the data but .Rmd files do facilitate echoing the code so that report readers can see how background operations were accomplished. The code chunk structure of these files can also nudge users towards including valuable comments (both between chunks and within them) though of course .Rmd files do not enforce such non-code content.\n\n\nR Markdowns - Potential Weaknesses\nR markdowns can fail to knit due to issues even when the code within the chunks works as desired. Duplicate code chunk names or a failure to install LaTeX can be a frustrating hurdle to overcome between functioning code and a knit output file. When code must be re-run repeatedly (as is often the case when developing a new workflow) the stop-and-start nature of running each code chunk separately can also be a small irritation.\n\n\nScript vs. Markdown Summary\nTaken together, both R scripts and R markdown files can empower users to write reproducible, transparent code. However, both file types have some key limitations that should be taken into consideration when choosing which to use as you set out to create a new code product."
  },
  {
    "objectID": "best_practices.html#file-paths",
    "href": "best_practices.html#file-paths",
    "title": "Best Practice Manuals",
    "section": "File Paths",
    "text": "File Paths\nThis section contains our recommendations for handling file paths on NCEAS analytical server. When sharing code collaboratively (e.g., with GitHub) managing the difference between your folder structure and those of your colleagues can be tackled in a variety of ways. Failing to account for this can result in annoying errors where content is either not read in successfully or is exported to the wrong folder. For content inside your working directory, we recommend using relative paths. However sometimes you need to read files from folders that are outside your working directory, for example large datasets shared among your team members.\nBelow are our recommendations for file path management in a team context; we hope they help!\n\n1) Preserve File Paths as Objects\nFirst and foremost, we recommend that you begin each script (just after loading your libraries) by saving all the paths to your files as objects. This makes it easy for each new user to remember that they might need to alter those objects so that data are read in and saved out to the appropriate places.\n\nmy_path <- \"path/to/my/file/\"\nmy_path\n\n[1] \"path/to/my/file/\"\n\n\n\n\n2) Use file.path() to Make Path Objects\nfile.path() is a useful base R function that automatically accounts for the fact that Mac and PC operating systems use different slashes between folder names to indicate a path (one uses ‘/’ and the other uses ‘\\’)\n\nmy_path <- file.path(\"path\", \"to\", \"my\", \"file\")\nmy_path\n\n[1] \"path/to/my/file\"\n\n\nNote that while you could use paste(..., sep = '/') instead, it does not account for the different slash between Mac and PC so file.path() is preferable.\n\n\n3) Use Path Objects when Reading/Writing Data\nNow that you’ve saved your paths as objects using file.path() to account for operating system differences, you should use them during import/export steps! To do this, just wrap the argument (i.e., part of the function) that deals with the file name/path in another call to file.path() with the object you created earlier and the name of the file to import/export. See below for two examples:\n\n# Import\nmy_raw_data <- read.csv(file = file.path(my_path, \"raw_data.csv\"))\n\n# Export\nwrite.csv(x = data_object, file = file.path(my_path, \"tidy_data.csv\"))\n\n\n\nFile Paths Summary\nWe strongly recommend preserving your file paths as objects at the start of your scripts (using file.path()) to ensure that your scripts can be shared as easily as possible among your team without issues due to user-specific folder names or computer operating system interrupting the work that you set out to do."
  },
  {
    "objectID": "best_practices.html#package-loading",
    "href": "best_practices.html#package-loading",
    "title": "Best Practice Manuals",
    "section": "Package Loading",
    "text": "Package Loading\nLoading packages / libraries in R can be cumbersome when working collaboratively because there is no guarantee that you all have the same packages installed. While you could comment-out an install.packages() line for every package you need for a given script, we recommend using the R package librarian to greatly simplify this process!\nlibrarian::shelf() accepts the names of all of the packages–either CRAN or GitHub–installs those that are missing in that particular R session and then attaches all of them. See below for an example:\nTo load packages typically you’d have something like the following in your script:\n\n## Install packages (if needed)\n# install.packages(\"tidyverse\")\n# install.packages(\"devtools\")\n# devtools::install_github(\"NCEAS/scicomptools\")\n\n# Load libraries\nlibrary(tidyverse); library(scicomptools)\n\nWith librarian::shelf() however this becomes much cleaner!\n\n# Install and load packages!\nlibrarian::shelf(tidyverse, NCEAS/scicomptools)\n\nWhen using librarian::shelf(), package names do not need to be quoted and GitHub packages can be installed without the additional steps of installing the devtools package and using devtools::install_github() instead of install.packages()."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Scientific Computing Support at NCEAS",
    "section": "",
    "text": "What We Do\nWe are a small (but mighty!) team of data scientists working at the National Center for Ecological Analysis and Synthesis (NCEAS). We primarily work with LTER (Long Term Ecological Research) Working Groups and provide all manner of data-adjacent assistance. This can include offering workshops on new skills or programs, helping you get set up on NCEAS’ server, acquiring data from third parties, or writing code to wrangle, analyze, or visualize the data your group has already collected. Depending on your team’s preferences, we can operate on a spectrum of independence ranging from complete self-sufficiency after initial definition of task scope to coding together with your team.\nPlease feel free to take a look at our NCEAS information page here as well."
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "Some of the content that we produce is not as detailed as our full workshops but has a wider scope than the content included in our “Best Practices” suggestions. This information can broadly be defined as “tutorials” though their depth and scope can vary significantly depending on the topic being tutorialized. As with our Best Practices, this page is under constant development so please post an issue if you have an idea for a tutorial that you’d like to suggest that we create."
  },
  {
    "objectID": "tutorials.html#building-a-website-with-quarto",
    "href": "tutorials.html#building-a-website-with-quarto",
    "title": "Tutorials",
    "section": "Building a Website with Quarto",
    "text": "Building a Website with Quarto\nQuarto is a new tool developed by RStudio (the company, not the program) to create a more ‘what you see is what you get’ editor for creating markdown files and products (e.g., books, websites, etc.). Additionally, it includes a visual editor that allows users to insert headings and embed figures via buttons that are intuitively labeled rather than through somewhat arcane HTML text or symbols. While Quarto is still in its infancy, it is rapidly gathering a following due to the aforementioned visual editor and for the ease with which quarto documents and websites can be created.\n\nPrerequisites\nTo follow along with this tutorial you will need to take the following steps:\n\nDownload R\nDownload RStudio\nDownload Quarto\nInstall git\nCreate a GitHub Account\nConnect git to GitHub\n\nFeel free to skip any steps that you have already completed!\n\n\nCreate a New R Project\nTo begin, click the “Project” button in the top right of your RStudio session.\n\nIn the resulting dialogue, click the “New Directory” option.\n\nFrom the list of options for project templates, select “Quarto Website”.\n\nPick a title and check the “Create a git repository” checkbox. For your title, short but descriptive titles are most effective. Once that is done, click “Create Project” in the bottom right of the window.\n\nAfter a few seconds, RStudio should refresh with a Quarto document (such documents have the file extension “.qmd”) and a “_quarto.yml” file open.\n\nPart of Quarto’s central philosophy is that all of the formatting of individual .qmd files in a project is governed by the settings created by a singular .yml file. In an R markdown project some of the global settings are set in .yml but other settings are handled within each .Rmd file. This centralization is a key innovation in streamlining projects and is one reason for Quarto’s quick popularity.\n\n\nPreparing Project for Web Deployment\nTo prepare your project for web deployment via GitHub Pages, we have three quick steps that we must first complete.\nFirst, in the “_quarto.yml” file, add output-dir: docs as a subheading beneath the project: heading. Make sure that the indentation is the same as the type: website but the new line can be either above or below that line.\n\nSecond, in the “Terminal” pane run touch .nojekyll. This creates a file called “.nojekyll” that is necessary for hosting your website via GitHub Pages.\nThird, in the “Terminal” pane run quarto render. This processes the template .qmd files you currently have in the repository and prepares them to become actual web pages.\nOnce you’ve done these three things you can move on to creating a GitHub repository so that we can take the necessary steps to having GitHub host your website!\n\n\nMake a New GitHub Repository\nFrom your GitHub “Repositories” tab, click the  green  “New” button.\n\nAdd a title to your repository and add a description. Once you’ve added these two things, scroll down and click the  green  “Create repository” button.\n\nBe sure that you do not add a README, do not add a gitignore, and do not add a license. Adding any of these three will cause a merge conflict when we link the project that you just created with the GitHub repository that you are in the process of creating.\n\nAfter a few seconds you should be placed on your new repository’s landing page which will look like the below image because there isn’t anything in your repository (yet).\nCopy the link in the field and go back to your RStudio session.\n\n\n\nAdding your Project to GitHub\nThe following steps include a sequence of command line operations that will be relayed in code chunks below. Unless otherwise stated, all of the following code should be run in “Terminal”.\nIf you didn’t check the “Create a git repository” button while creating the R project, you’ll need to do that via the command line now. If you did check that box, you should skip this step!\n\n# Start a git repository on the \"main\" branch\ngit init -b main\n\nStage all of the files in your project to the git repository. This includes the .yml file, all .qmd files and all of their rendered versions created when you ran quarto render earlier. This code is equivalent to checking the box for the files in the “Git” pane of RStudio.\n\n# Stage all files\ngit add .\n\nOnce everything has been staged, you now must commit those staged files with a message.\n\n# Commit all files with the message in quotes\ngit commit -m \"Initial commit\"\n\nNow that your project files have been committed, you need to tell your computer where you will be pushing to and pulling from. Paste the link you copied at the end of the “Make a New GitHub Repository” into the code shown in the chunk below (inside of the [...]) and run it.\n\n# Tell your computer which GitHub repository to connect to\ngit remote add origin [GITHUB_URL]\n\nVerify that URL before continuing.\n\n# Confirm that URL worked\ngit remote -v\n\nFinally, push your commited changes to the repostory that you set as the remote in the preceding two steps.\n\n# Push all of the content to the main branch\ngit push -u origin main\n\nNow, go back to GitHub and we can get your website deployed!\n\n\nDeploy Website via GitHub\n\n\nGitHub Housekeeping\n\n\nAdding Content\nRAW CONTENT BELOW (vvv)\nOpen up RStudio and go to File -> New Project -> New Directory -> Simple R Markdown Website and then fill in the following boxes to name and save your website source code wherever you would like.\n\n\n\n\nAfter you click “Create Project”, you should see three files in your RStudio window: _site.yml, about.Rmd, and index.Rmd. The idea is that each R Markdown (.Rmd) file will be a “page” in our website, and the .yml file will contain instructions on how to combine these pages together.\n\nindex.Rmd: This demo R Markdown file will be our website’s “home” page.\nabout.Rmd: This demo R Markdown file will be our website’s “about” page.\n_site.yml: This a configuration file: We’ll use this to change how our website looks;\nNote: When building a website, R Markdown only looks for the files index.Rmd and _site.yml. So change the contents of these files however you like, but don’t change the name! On the other hand, feel free the change the name of about.Rmd to whatever you’d like!\n\nTo build the demo website, we can go to the Build Pane on RStudio (typically in the top right) and press “Build Website”. Alternatively, we can run the command rmarkdown::render_site() in the console.\n\nThis will create a new folder called _site in the working directory with our website! To see what it looks like, go into the new _site folder and open up either the index.html or the about.html file in your web browser. Clicking on the “Home” tab, you should see something like this:\n\n\nNow that we have an idea of how the demo works, let’s start personalizing it!"
  },
  {
    "objectID": "tutorials.html#updating-the-website",
    "href": "tutorials.html#updating-the-website",
    "title": "Tutorials",
    "section": "Updating the website",
    "text": "Updating the website\n\nChanging output directory\nFirst of all, the folder where our website lives was called _site. We can change this name to be anything, but let’s keep it simple and call it docs: Go into our _site.yml file and add in output_dir: \"docs\" underneath the name of the project.\n\nNow we can build the website again (either clicking “Build Website” or running rmarkdown::render_site()) and notice that we made a folder called docs instead of _site! We can even safely delete the old _site folder, since our website will now always be built and updated into the docs folder.\n\n\nAdding a page to the website:\nCreate an R Markdown file (you can name it whatever you want, but ours is called practice.Rmd) containing all of the information you want in that page. Make sure that you have output: html_document in the header!\n\nOnce your page is all filled up, go into the _site.yml file and add the following underneath the other pages:\n\ntext: \"<page name to be displayed>\"\nhref: <name of rmd file you just made>.html\n\nFor example,\n\nThen if we build our website again, we can see our new page!"
  },
  {
    "objectID": "tutorials.html#additional-features",
    "href": "tutorials.html#additional-features",
    "title": "Tutorials",
    "section": "Additional Features",
    "text": "Additional Features\nIf you want to get fancy with styling the website, it helps to know some HTML or CSS. Here are a few examples of some of the things you can do:\n\nApply a theme\nTo apply an HTML/CSS change to every page of your website, we can add an output section to our _site.yml file.\nFor example, to change the theme of our website to Bootswatch’s “flatly” theme, we can apply like it like so:\n\nLet’s see what our website looks like now!\n\n\nYou can see more bootswatch themes here.\n\n\nAdd a footer\nIf we want to add a footer to the website, make an HTML (or RHTML) document with the footer, like so:\n\nThen we can add this footer to our website by adding an include section to the output in _site.yml, like so\n\nThen if we build our website again, we can see the footer at the bottom of every page\n\n\nNote: For more themes and styling options, look at Section 3.1.4 here\nFor more information on building a website, see Chapter 10.5 of https://bookdown.org/yihui/rmarkdown/rmarkdown-site.html"
  },
  {
    "objectID": "staff.html",
    "href": "staff.html",
    "title": "Our Team",
    "section": "",
    "text": "Because we live in an era where we may only meet in person sporadically, we felt it would be nice to introduce ourselves here to help you put a face to the emails / Slack messages / GitHub issues we exchange going forward! If you would like to email the whole team as one send your questions to scicomp@nceas.ucsb.edu"
  },
  {
    "objectID": "staff.html#julien-brun",
    "href": "staff.html#julien-brun",
    "title": "Our Team",
    "section": "Julien Brun",
    "text": "Julien Brun\nbrunj7.github.io –  brunj7 –  @brunj7 – brun@nceas.ucsb.edu\n\nAs a senior data scientist, the core of Julien’s work is to understand the data and computing challenges researchers are facing and help them to translate these challenges into solvable tasks. Julien advises and mentors on how to clean, structure, combine, and analyze their heterogeneous data sets, as well as scaling up their analysis while promoting open and reproducible data science principles.\nJulien is also a Lecturer in the Master in Environmental Data Science program at Bren School of Environmental Science and Management at UC Santa Barbara, where he teaches “good enough” practices in reproducible and collaborative data science."
  },
  {
    "objectID": "staff.html#angel-chen",
    "href": "staff.html#angel-chen",
    "title": "Our Team",
    "section": "Angel Chen",
    "text": "Angel Chen\n angelchen7 – anchen@nceas.ucsb.edu\n\nAngel supports LTER synthesis working groups by developing data pipelines and reproducible analytical workflows to integrate various sources of data. Angel previously worked as a data curator for the Arctic Data Center, helping researchers archive and store their data. Angel recently completed a B.S. in statistics & data science at the University of California, Santa Barbara."
  },
  {
    "objectID": "staff.html#nick-lyon",
    "href": "staff.html#nick-lyon",
    "title": "Our Team",
    "section": "Nick Lyon",
    "text": "Nick Lyon\nnjlyon0.github.io –  njlyon0 –  @scilyon – lyon@nceas.ucsb.edu\n\nNick focuses on supporting LTER synthesis working groups in the acquisition and management prerequisite to analysis and visualization. Nick is a trained restoration ecologist focusing on interacting communities of plants and insects and has extensive experience taking “raw” field-collected data and readying it for hypothesis testing in a rigorous, transparent way. Nick completed his MS in Ecology and Evolutionary Biology at Iowa State University"
  },
  {
    "objectID": "onboarding.html",
    "href": "onboarding.html",
    "title": "Onboarding",
    "section": "",
    "text": "This page contains a quick, cookbook-style set of instructions for new staff on the Scientific Computing Team. We are so excited to have you join us and we hope that these instructions are clear and easy-to-follow. Please don’t hesitate to reach out if you run into any issues (see the “Our Team” tab of this site) or post a GitHub issue yourself on this website’s repository!\nListed below are a mix of references and tutorials on concepts we aim to promote to researchers who we support, as well as tools and workflows we use in our team. The goal is to give context about open and reproducible science principles NCEAS is promoting to the scientific community. You will also find information on getting access to the tools that you will need and some general information about working at NCEAS."
  },
  {
    "objectID": "onboarding.html#background-reading-material",
    "href": "onboarding.html#background-reading-material",
    "title": "Onboarding",
    "section": "Background Reading Material",
    "text": "Background Reading Material\n\nHampton et al 2015. “The Tao of open science for ecology”\nBorer et al 2009. “Effective Data Management”\nFegraus et al 2005. “Maximizing the Value of Ecological Data with Structured Metadata:”\nHeidborn 2008. “Shedding Light on the Dark Data in the Long Tail of Science”"
  },
  {
    "objectID": "onboarding.html#programs-resources",
    "href": "onboarding.html#programs-resources",
    "title": "Onboarding",
    "section": "Programs & Resources",
    "text": "Programs & Resources\n\nGitHub Tutorial\nWe rely heavily on GitHub for collaboration, and there are a few things you must do to get set up. First, complete the NCEAS GitHub Tutorial here. This tutorial will help you with getting started with git and GitHub using RStudio.\n\n\nLTER GitHub Organization\nRegister (if you have not already) for a personal GitHub account and send your username to Julien to be added to the LTER GitHub. This GitHub Organization “owns” the working groups repositories that you will be directly working with so being added to this organization will give you access to needed repositories.\n\n\nNCEAS GitHub Enterprise Organization\nWe use a GitHub Enterprise account to keep track of tasks for the Scientific Computing Support of LTER working groups. To be added to the account you must create an NCEAS account.\nFollow the directions outlined here and send your username to Julien Brun (not the email outlined in the Google Doc).\nAfter you have been added, you will be able to access the Issues tab of the lter-wg-scicomp GitHub repository. We use issues on this repository to keep track of tasks and projects as well as who is primarily responsible for a given task and which working group gave us the task initially.\n\n\nSlack\nWe use Slack to communicate with one another throughout the day. To be added to the NCEAS Slack group, register here. If you already have a slack account, be sure to use the email address you used to register.\nFind and join our #scicomp channel by clicking the plus sign next to the Channels section. Feel free to join any other channels that you might find interesting! Popular channels include #diversity, #nceas, and #social.\nFinally, complete this short tutorial on using Slack.\n\n\nNCEAS Server: Aurora\nWe use the Aurora server (located at aurora.nceas.ucsb.edu) when working with RStudio or JupyterHub. Send an email to help@nceas.ucsb.edu requesting an account mentioning you are working with Julien. Thomas Hetmank or Nick Outin will contact you with directions for setting up an account."
  },
  {
    "objectID": "onboarding.html#recurring-nceas-meetings",
    "href": "onboarding.html#recurring-nceas-meetings",
    "title": "Onboarding",
    "section": "Recurring NCEAS Meetings",
    "text": "Recurring NCEAS Meetings\nThere are a number of recurring meetings that you are encouraged to attend. At your hiring, you should recieve an invitation to the NCEAS Google Calendar which has links to all the meeting information. These include Coffee Klatch (a coffee social), Hacky Hours, and Data Science Chats (to name a few).\nWe also have a team Google Calendar to manage team events. Julien will add you if you have not been already."
  },
  {
    "objectID": "onboarding.html#data-science-background-and-tutorials",
    "href": "onboarding.html#data-science-background-and-tutorials",
    "title": "Onboarding",
    "section": "Data Science Background and Tutorials",
    "text": "Data Science Background and Tutorials\nFor good background information on the tools that we use, read through and practice examples of the following chapters from a training we did for postdocs in early 2020: https://science-for-nature-and-people.github.io/2020-data-collab-workshop/2020-02-snapp/index.html\nChapters 3, 5, 8 are a good background about the tools we use.\nChapters 9, 10 are a good introduction to data modeling.\n\nR Self-Assessment\nFinally, please complete this R Training Assessment to self-assess your skills in R.\nSchedule a session with Julien to debrief on your experience."
  },
  {
    "objectID": "onboarding.html#hr-related-resources",
    "href": "onboarding.html#hr-related-resources",
    "title": "Onboarding",
    "section": "HR-related Resources",
    "text": "HR-related Resources\n\nReporting Hours & Kronos\nWe submit vacation and sick day hours online through Kronos. You should receive an email at the start of your employment adding you to an email listserv that will send reminders on when to approve each month’s timesheet.\n\n\nUC Path\nUC Path is the online HR portal and can be accessed with your UCSB Net ID. It is where you can access things like your paycheck, next date of paycheck, and benefits (if applicable)."
  }
]